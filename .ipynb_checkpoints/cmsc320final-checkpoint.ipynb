{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Tutorial - The Data Science Process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to teach you how to use the entire data science pipeline in a real life situation. The data science pipeline consists of 5 steps: Data collection, Data processing, Exploratory analysis and data visualization,Analysis, Hypothesis testing and machine learning and lastly Insight and decision. We will use python to carry out the various techniques of predicting financial market movements, specifically stock prices.\n",
    "\n",
    "Our first technique will be using linear regression to predict the closing prices of stocks based on closing prices of the stocks in the past. We will predict the closing price of Microsoft's stock (ticker: MSFT) based on historical financial data from May 16, 2015 to April 16, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Project Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data will be retrieved from Yahoo Finance. The csv file is named as \"MSFT.csv\".For some background on the stock market to better understand how it actually works check out this link which explains the stock market with a cool infographic http://www.timothysykes.com/blog/stock-market-basics-tutorial-infographic/\n",
    "\n",
    "In order to collect this data with iPython notebook. We will begin the project by importing the necessary libraries. We will use Python Data Analysis Library (Pandas) and NumPy, a fundamental package for scientific computing with Python.\n",
    "\n",
    "Next we will load and manage data about stocks which we will use for our analysis. Then we will use the data and various libraries to perform exploratory data analysis.Last to predict the stock market we will be using Linear Regression. Linear Regression is a way of modeling a relationship between a independent and dependent variable by creating a linear equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Microsoft Corporation (MSFT) Historical Prices csv file from Yahoo Finance: https://finance.yahoo.com/quote/MSFT/history?p=MSFT. Then upload the csv file into the same folder as this file.Finally you can then load the data using panda's built in read_csv function which will read in the csv file and return a data structure we can perfom analysis one.Since we are interested in predicting the closing price we will isolate the Open and Close column into two seperate arrays using numpys built in array feature.\n",
    "\n",
    "Luckily, our data is already tidy. We do not need to worry about how to deal with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-18</td>\n",
       "      <td>47.980000</td>\n",
       "      <td>48.220001</td>\n",
       "      <td>47.610001</td>\n",
       "      <td>48.009998</td>\n",
       "      <td>48.009998</td>\n",
       "      <td>24136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>47.560001</td>\n",
       "      <td>47.810001</td>\n",
       "      <td>47.180000</td>\n",
       "      <td>47.580002</td>\n",
       "      <td>47.580002</td>\n",
       "      <td>28574800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>47.389999</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>47.270000</td>\n",
       "      <td>47.580002</td>\n",
       "      <td>47.580002</td>\n",
       "      <td>25047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>47.279999</td>\n",
       "      <td>47.599998</td>\n",
       "      <td>47.009998</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>22410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>47.299999</td>\n",
       "      <td>47.349998</td>\n",
       "      <td>46.820000</td>\n",
       "      <td>46.900002</td>\n",
       "      <td>46.900002</td>\n",
       "      <td>25720600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2015-05-18  47.980000  48.220001  47.610001  48.009998  48.009998  24136500\n",
       "1  2015-05-19  47.560001  47.810001  47.180000  47.580002  47.580002  28574800\n",
       "2  2015-05-20  47.389999  47.930000  47.270000  47.580002  47.580002  25047900\n",
       "3  2015-05-21  47.279999  47.599998  47.009998  47.419998  47.419998  22410700\n",
       "4  2015-05-22  47.299999  47.349998  46.820000  46.900002  46.900002  25720600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MSFT.csv')\n",
    "size = len(df.index)\n",
    "data_range = np.arange(size)\n",
    "train_x = np.array(df[\"Open\"]).reshape(size,1)\n",
    "train_y = np.array(df[\"Close\"]).reshape(size,1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis and Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis is a way of analyzing a set of data in order to gain knowledge about its characterstics, such as basic summary statistics, distribution, and obvious trends to see if there are any problems with the data. \n",
    "You can also use it to prepare the data for modeling as we will be doing in the case of this project.This can be accomplished by creating visualizations, getting basic descriptions of the data and identifying patterns.For a more in depth explanation of Exploratory Data Analysis check out this site which explains the basics of exploratory data analysis.\n",
    "\n",
    "http://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is importated we can begin to explore your data efficiently so that we then use the information gained from our analysis in order to start modeling our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is imported we can begin to explore your data efficiently so that we then use the information gained from our analysis in order to start modeling our data. A great way to start analysing data is by finding averages such as the mean and median of the opening and closing prices of Microsoft Stock so we can learn where the majority of our data lies.Another measure of  central tendency we should find is the the variance.We will find the varience of our data so we can learn the range of the data.We can find all of our central tendencies using panda's built in mean,median,and variance function on our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the opening price: 54.2568672676\n",
      "The median of the opening price: 54.1000005\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unbound method var() must be called with DataFrame instance as first argument (got Series instance instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ed9db59c74f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mopening_price_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The median of the opening price: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopening_price_median\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopen_price_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The variance of the opening price: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_price_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The max of the opening price: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unbound method var() must be called with DataFrame instance as first argument (got Series instance instead)"
     ]
    }
   ],
   "source": [
    "opening_price_mean = df[\"Open\"].mean()\n",
    "print(\"The mean of the opening price: \" + str(opening_price_mean))\n",
    "opening_price_median = df['Open'].median()\n",
    "print(\"The median of the opening price: \" + str(opening_price_median))\n",
    "open_price_variance = pd.DataFrame.var(df['Open'])\n",
    "print(\"The variance of the opening price: \" + str(open_price_variance))\n",
    "print(\"The max of the opening price: \" + str(df.xs('Open', axis=1).max()))\n",
    "print(\"The min of the opening price: \" + str(df.xs('Open', axis=1).min()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opening_price_mean = df[\"Close\"].mean()\n",
    "print(\"The mean of the closing price: \" + str(opening_price_mean))\n",
    "opening_price_median = df['Close'].median()\n",
    "print(\"The median of the closing price: \" + str(opening_price_median))\n",
    "open_price_variance = pd.DataFrame.var(df['Close'])\n",
    "print(\"The variance of the closing price: \" + str(open_price_variance))\n",
    "print(\"The max of the closing price: \" + str(df.xs('Close', axis=1).max()))\n",
    "print(\"The min of the closing price: \" + str(df.xs('Close', axis=1).min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gathering the mean,median and variance of our data we can see that there is a large variance. This indicates indicates that the data points are very spread out from the mean.In order to understand exactly how spread out our data is we should visualize the data. A simple way to do this is to create a plot using matplotlib.pyplot as plt.Since the goal of our project is to predict the closing price we will focus on ploting the closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_fig = plt.figure()\n",
    "correlation_fig.suptitle('Distribution of Closing Prices Across Time', fontsize=12)\n",
    "plt.plot(data_range,train_y)\n",
    "plt.title('May 16, 2015 to April 16, 2017')\n",
    "plt.ylabel('Closing Price', fontsize=14)\n",
    "plt.xlabel('Date Range', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our visualization does show us that the data is very spread out.Although its hard to learn anything else about the data because there doesnt seem to be a correlation between microsoft stock closing prices and time.A different type of visualization may help us to gain more information. We will next plot the normal distrubtion of MST closing prices across time. A normal distrubtion plot is useful because if the data is normally distrubted we can easily predict unknown values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_mean = np.mean(train_y )\n",
    "y_std = np.std(train_y)\n",
    "\n",
    "correlation_fig = plt.figure()\n",
    "pdf = stats.norm.pdf(train_y,y_mean, y_std)\n",
    "plt.plot(train_y, pdf) \n",
    "\n",
    "correlation_fig.suptitle('Distribution of MSFT Closing Prices Across Time', fontsize=12)\n",
    "plt.xlabel('Closing Price', fontsize=11)\n",
    "plt.ylabel('Distrubtion', fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of MSFT closing prices shows that the closing prices are not normally distrubtued. We will have to analyze our data more in order to determine how to predict closing prices. \n",
    "\n",
    "A well-known visualization for analyzing financial data is a candle stick chart. Candle Stick charts shows all known information know about the price of the stock. The green candlesticks represent days when the closing price increased in value and the red candelsticks represent days with a decreasing value. For information how how to interperct Candle Stick Charts check out this website: http://stockcharts.com/school/doku.php?id=chart_school:chart_analysis:introduction_to_candlesticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode()\n",
    "from datetime import datetime\n",
    "\n",
    "trace = go.Candlestick(x=df.index,\n",
    "                       open=df.Open,\n",
    "                       high=df.High,\n",
    "                       low=df.Low,\n",
    "                       close=df.Close)\n",
    "data = [trace]\n",
    "layout = {\n",
    "    'title': 'Microsoft Stock ',\n",
    "    'yaxis': {'title': 'Microsoft Stock'},\n",
    "    'shapes': [{\n",
    "        'x0': '2015-05-16', 'x1': '2017-4-16',\n",
    "        'y0': 0, 'y1': 1, 'xref': 'x', 'yref': 'paper',\n",
    "        'line': {'color': 'rgb(30,30,30)', 'width': 1}\n",
    "    }],\n",
    "    'annotations': [{\n",
    "        'x': '2015-05-16', 'y': 0.05, 'xref': 'x', 'yref': 'paper',\n",
    "        'showarrow': False, 'xanchor': 'left',\n",
    "        'text':''\n",
    "    }]\n",
    "}\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='aapl-recession-candlestick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find great insight from Microsoft's historic financial data by plotting moving averages based on close prices. We will be re-introducing the graph used earlier when visualizing the distribution of close prices across time. Take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fifteen_day = pd.rolling_mean(df[\"Close\"], 15)\n",
    "fifty_day = pd.rolling_mean(df[\"Close\"], 40)\n",
    "twohundred_day = pd.rolling_mean(df[\"Close\"], 120)\n",
    "\n",
    "plt.plot(data_range,train_y)\n",
    "plt.plot(data_range,fifteen_day)\n",
    "plt.plot(data_range,fifty_day)\n",
    "plt.plot(data_range,twohundred_day)\n",
    "plt.title('Close Prices Along w/ Moving Averages from May 16, 2015 to April 16, 2017')\n",
    "plt.ylabel('Closing Price', fontsize=14)\n",
    "plt.xlabel('Date Range', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this illustration, we're using a cross strategy with 3 different interval of days for moving averages: 15, 40 and 120. Notice that the 40-day and 120-day moving average is slower to adjust to price changes because it uses more data points in its calculation while the 15-day is quicker to respond due to each value having a greater weight in the calculation from the shorter time horizon. \n",
    "\n",
    "As you can see from this cross strategy, you would watch for the 15-day (orange) average to cross below the 40-day (green) moving average as an entry for a short position.\n",
    "\n",
    "Another insight derived from this cross strategy is momentum. Whenever the shorter term moving average is above the longer term, it confirms upward momentum. We can see there's an upward momentum after the 350 date range mark. This is a great indication to hold on to your stocks as it's a good chance the prices would continue to rise.\n",
    "\n",
    "Moving averages is a excellent tool to spot trends because noise can be eliminated by properly adjusting the day intervals. You can learn more about analyzing moving averages here: http://www.investopedia.com/articles/technical/052201.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool feature worth plotting is the average change of closing prices each month. This is calculated by grouping each day's closing price by their respective months and averaging them. Here's how we've done so. I would be using the financial data from May 16, 2015 to April 16, 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "datetime_range = df[\"Date\"].apply(lambda x: parser.parse(\"{} 11:00PM\".format(x))) # create datetime-like objects from Date column\n",
    "df.set_index(datetime_range, inplace=True)\n",
    "monthly = df.resample('BM').mean() # group rows by month and average them\n",
    "returns = monthly.xs(('Close'), axis=1).pct_change() # calculate return percentages from these averages for each month\n",
    "\n",
    "print returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_fig = plt.figure()\n",
    "plt.scatter(np.arange(len(monthly)),returns)\n",
    "correlation_fig.suptitle('Returns of MSFT Closing Prices Across Months', fontsize=12)\n",
    "plt.xlabel('Month Range', fontsize=11)\n",
    "plt.ylabel('Return on MSFT Stock', fontsize=11)\n",
    "plt.plot(np.arange(len(monthly)),returns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this kind of illustration you can see how Microsoft is doing at a month-to-month basis. Microsoft's close price took a substantial positive turn at the end of September, 2015 into October, 2015. Conversely, it began to take a negative turn during the months November to January in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 4: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a form of regression analysis.The goal of Linear Regression is to find a relationship between a set of independent and dependent variables in order to create a Mathematical linear function that can be used to predict depedent values for any given independent value.To learn about linear regression more in depth check out the the following page which explins the basics of linear regression.\n",
    "\n",
    "http://www.statisticssolutions.com/what-is-linear-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create our Linear Regression model using linear_models built in LinearRegression function. Next we will \n",
    "we train our model using the open prices from May 16, 2015 to April 16, 2017 as our independent variable and their closing prices as our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_mod = linear_model.LinearRegression() \n",
    "linear_mod.fit(train_x,train_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use this trained model to predict the close prices from April 16, 2017 to present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('MSFT2.csv')\n",
    "size = len(df2.index)\n",
    "actual_close = np.array(df2[\"Close\"])\n",
    "#test_X = df2.as_matrix()\n",
    "test_X = np.array(df2[\"Open\"]).reshape(size,1)\n",
    "predicted_price = linear_mod.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_range = np.arange(size)\n",
    "plt.plot(data_range, predicted_price)\n",
    "plt.plot(data_range, actual_close)\n",
    "plt.legend(['predicted closing', 'actual closing'], loc='upper left')\n",
    "plt.title('Close Price Forecast from April 16, 2017 to Present')\n",
    "plt.ylabel('Closing Price', fontsize=14)\n",
    "plt.xlabel('Date Range', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "#print \"predicted closing price: {}\".format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for analysis purposes only. This isn't really a useful tool because we can only see the patterns of close prices in hindset. It would be more convenient if we can predict open prices for later dates so that we can forecast the closing prices of those later dates.\n",
    "\n",
    "One way I can implement this is by incrementally predicting opening and closing prices until I reached a desired date. I would need a separate predicter for guessing closing and opening prices. \n",
    " \n",
    "[Implementation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another disclaimer: stocks are deeply impacted by the news. Just this past Wednesday, Snap release a report about their not-as-anticipated slow user growth. Their stock fell as much as 25% hours later. Therefore, past stock prices can not predict future prices because news events have different magnitudes of effect on stock and they happen at arbitrary dates. \n",
    "\n",
    "There are two solutions. We can use a tool that does a sentiment analysis on present-day news to predict the closing stock price or we can predict news events in the future and their respective magnitudes of influence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
